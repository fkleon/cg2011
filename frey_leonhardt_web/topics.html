 <!--
Design by Bryant Smith
http://www.bryantsmith.com
http://www.aszx.net
email: template [-at-] bryantsmith [-dot-] com
Released under Creative Commons Attribution 2.5 Generic.  In other words, do with it what you please; but please leave the link if you'd be so kind :)

Name       : An Ocean of Sky
Description: One column, with top naviation.  All divs, validations: XHTML Strict 1.0 & CSS
Version    : 1.0
Released   : 20081009
-->


<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="anoceanofsky.css" />
<title>A Dragon's tale</title>
</head>

<body>
    <div id="page">
        <div class="topNaviagationLink"><a href="index.html">Home</a></div>
        <div class="topNaviagationLink"><a href="topics.html">Topics</a></div>
	</div>
    <div id="mainPicture">
    	<div class="pictureTopics">
        	<div id="headerTitle">A Dragon's Tale</div>
            <div id="headerSubtext">Implemented Topics</div>
        </div>
    </div>
        <div class="contentBox">
    	<div class="innerBox">
        
	<a name="topic_dof"></a>
	<div class="contentTitle">Depth of Field (20 Points)</div>
        <div class="contentSubTitle">- Advanced Camera Properties -<br/>Implemented by Frederik Leonhardt</div>
	<div class="contentSubSubTitle">Description</div>
          <div class="contentText">
	  <p>Depth of field using a thin lens camera model. The effect can be observed at the far end of the room (tail of the dragon) and on the water.</p>
	  </div>

	<div class="contentSubSubTitle">Implementation</div>
 	  <div class="contentText">
	  <p>We introduced a new Camera model, the Perspective Lens Camera. To operate correctly, it needs to be initialized with additional parameters:</p>
	  <ul>
	  <li><p>The <i>aperture</i> determines the size of the lens, and an aperture of 0 will simluate a pin hole camera. A big aperture yields a narraw depth of field.</p></li>
	  <li><p><i>Focal length</i> defines the distance to the focal plane, i.e. all objects on this plane will be in focus.</p></li>
	  <li><p><i>Lens distance</i> (from the image plane) has to be bigger than the focal length, or our camera would look backwards. Varying the lens distance will zoom into/out of the scene.</p></li>
	  <li><p><i>Number of samples</i>. To achieve a depth of field effect, we send random rays from the lens surface into the scene towards the focal point. Increasing the number of samples will lead to a smoother effect, but cause a rather big impact on rendering time.</p></li>
	  <li><p>Additionally you can specify, whether the camera should <i>auto-focus</i> on the lookAt-Point. This will automatically adjust the focal length, so that the point specified is in focus. This improves ease of use dramatically ;)</p></li>
	  </ul>
	  You can find the implementation in <i><u>impl/perspective_camera.h</u></i>
	  </div>

	<div class="contentSubSubTitle">Example</div>
    	<div id="inlinePicture">
    		<div class="dof_picture"></div>
    	</div>

	<div class="contentSubSubTitle">References</div>
          <div class="contentText">
	  [1] Philipp Slusallek, Computer Graphics Lecture WS2011/12: Camera Transformations, p. 13ff<br/>
	  [2] <a href="http://http.developer.nvidia.com/GPUGems/gpugems_ch23.html" target="_blank">NVIDIA: GPU Gems, chapter 23</a>
	  </div>


	<br/><hr />

	<a name="topic_refr"></a>
        <div class="contentTitle">Reflective and Refractive Transparency (30 Points)</div>
        <div class="contentSubTitle">- Surface Shading -<br/>Implemented by Frederik Leonhardt</div>
	<div class="contentSubSubTitle">Description</div>
          <div class="contentText">
	  <p>Using Snell's law we can calculate the refraction ray from an incoming ray and refraction index of the material, and Fresnel's term tells us how much light is being refracted and reflected. If the contribution of the reflection is smaller than 0,5%, only refractance is being considered. Also the case of toternal internal reflection is handled correctly.</p>
	  <p>To simplify rendering, we assume that any material is surrounded by air at sea level (refraction index of 1,00029).</p>
 	  <p>The effect can be observed in the two glass spheres, the diamond and the water.</p>
	  </div>

	<div class="contentSubSubTitle">Implementation</div>
 	  <div class="contentText">
	  <p>The RefractivePhongShader handles transparent materials. The <i>refraction index</i> and <i>transparency</i> can be set according to the material properties. To be able to display more realistic shadows for transparent objects we introduced Shadow Rays and modified the Integrator, so that it can recognize transparent materials when checking if an light source is visible from a hit point. If a transparent material is found, we use the materials transparency to dim the ray's intensity and again send the ray towards the lightsource (with a little offset on the hitpoint in the ray's direction).</p>
	  <p></p>
	  You can find the implementation in <i><u>impl/phong_shaders.h</u></i>, <i><u>core/ray.h</u></i> and <i><u>impl/integrator.h</u></i>.
	  </div>

	<div class="contentSubSubTitle">Example</div>
    	<div id="inlinePicture">
    		<div class="refr_picture"></div>
    	</div>
          <div class="contentText">See also examples at <a href="#topic_dof">Depth of Field</a> and <a href="#topic_bump">Bump Mapping</a> </div>    	

	<div class="contentSubSubTitle">References</div>
          <div class="contentText">
	  [1] Matt Pharr, Greg Humphreys: Physically Based Rendering, Second Edition: From Theory To Implementation, Morgan Kaufmann USA, 2010, p. 434ff<br/>
	  [2] <a href="http://http.developer.nvidia.com/GPUGems/gpugems_ch23.html" target="_blank">NVIDIA: GPU Gems, chapter 23</a>
	  </div>
        
	<br/><hr />

	<a name="topic_proc"></a>
        <div class="contentTitle">Procedural Shading (20 Points)</div>
        <div class="contentSubTitle">- Surface Shading -<br/>Implemented by Frederik Leonhardt & Michael Frey</div>
	<div class="contentSubSubTitle">Description</div>
          <div class="contentText">
	  <p>Different noise functions can be used to generate a base for procedural 3d textures. A very convenient way is the Perlin Noise, described by Ken Perlin. We use his reference implementation in our project.</p>
	  <p>This noise can be processed in many different ways, for example for a simple water texture we just use a stripe function, which is basically a sin-function on the perlin noise.</p>
 	  <p>Procedural shading is used for texturing our scene. The dragon has a procedural marble texture, and the podium uses a procedural wooden texture. Also water and floor are textured with procedural textures. A procedural planet texture is applied to the biggest sphere on the left.</p>
	  <p>Initially we didn't even plan to implement procedural shading, but in the end we found this topic to be very interesting. The planetary texture was a first try to implement a more complex procedural texture, but sadly we didn't have the time to dive deeper into this topic.</p>
	</div>

	<div class="contentSubSubTitle">Implementation</div>
 	  <div class="contentText">
	  <p>First we introduced a new texture type: ProceduralTexture. This is a base class for all other procedural texture, and contains methods to sample the 3d texture at a given point, and also supports generating a bump texture for every procedural texture.</p>
	  <p>Also new shaders are necessary to process this new texture type. We have three different shaders:</p>
	  <ul>
	  <li><i>ProceduralRefractiveBumpShader</i>: Generates bump map for water</li>
	  <li><i>ProceduralBumpShader</i> & <i>ProceduralHardBumpShader</i>: They only differ in the generated bump maps, one produces "harder" bumps.
	  </ul>
	  <p>We implemented a procedural water texture (for bump mapping the water), a marble texture, a wooden texture and a planetary texture (as described in "Texturing and Modeling, Third Edition: A Procedural Approach"). </p>
	  You can find the implementation in <i><u>rt/texture.h</u></i> and <i><u>impl/phong_shaders.h</u></i>.
	  </div>

	<div class="contentSubSubTitle">Examples</div>
    	<div id="inlinePicture">
    		<div class="proc_picture"></div>
    	</div>
          <div class="contentText">Water, dragon and podium textures are generated procedurally.</div>    	
    	<div id="inlinePicture">
    		<div class="proc_picture2"></div>
    	</div>
          <div class="contentText">Testing our procedural bump shader.</div>

	<div class="contentSubSubTitle">References</div>
          <div class="contentText">
	  [1] David S. Ebert, F. Kenton Musgrave, Darwyn Peachey, Ken Perlin, Steve Worley: Texturing and Modeling, Third Edition: A Procedural Approach, Morgan Kaufmann USA, 2002<br/>
	  [2] <a href="http://freespace.virgin.net/hugo.elias/models/m_perlin.htm" target="_blank">Hugo Elias: Perlin Noise</a><br/>
	  [3] <a href="http://mrl.nyu.edu/perlin/">Ken Perlin</a>'s Homepage
	  </div>
	<br/><hr />

	<a name="topic_bump"></a>
        <div class="contentTitle">Bump Mapping (30 Points)</div>
        <div class="contentSubTitle">- Texturing -<br/>Implemented by Frederik leonhardt</div>
	<div class="contentSubSubTitle">Description</div>
          <div class="contentText">
	  <p>Bump mapping is the pertubation of the normal vector based on a height map (bump texture). The rendered image looks geometrically more detailed.</p>
	  </div>

	<div class="contentSubSubTitle">Implementation</div>
<div class="contentText">
	  <p>We added a TexturedPhongShader, which handles normal textures and bump textures. The getNormal() function is modified, so that the shader samples the bump texture first, then calculates an orthonormal base to our original normal and finally uses the derivations extracted from the bump texture to pertube the normal.</p>
	  <p>We added a new texture type <i>TT_HeightMap</i> and a method to sample this texture, which returns a vector. The shader doesn't need to take care of sampling, it is being handled in the texture itself.</p>
	  <p>You can find the implementation in <i><u>impl/phong_shaders.h</u></i>, <i><u>rt/texture.h</u></i> and <u><i>impl/lwobject_reader.cpp</u></i>.</p>
	  </div>

	<div class="contentSubSubTitle">Examples</div>
    	<div id="inlinePicture">
    		<div class="bump_picture"></div>
    	</div>
          <div class="contentText">The stone texture is bump mapped. See also examples at <a href="#topic_proc">Procedural shading</a>.</div>   
	
	<div class="contentSubSubTitle">References</div>
          <div class="contentText">
	  [1] Matt Pharr, Greg Humphreys: Physically Based Rendering, Second Edition: From Theory To Implementation, Morgan Kaufmann USA, 2010<br/>
	  [2] Philipp Slusallek, Computer Graphics Lecture WS2011/12<br/>
	  </div>
	<br/><hr />

	<a name="topic_sah"></a>
        <div class="contentTitle">SAH construction of BVH (20 Points)</div>
        <div class="contentSubTitle">- Optimization Techniques -<br/>Implemented by Frederik Leonhardt</div>
	<div class="contentSubSubTitle">Description</div>
          <div class="contentText">
	  <p>Using the <i>Surface Area Heuristic</i> to determine the split position of a BVH node instead of splitting in the middle or at the median leads to a faster traversal, because ideally large and almost empty cells will be favoured by the algorithm.</p>
	  </div>

	<div class="contentSubSubTitle">Implementation</div>
<div class="contentText">
	  <p>A new structure for binary space partitioning accelerators has been introduced by us: BVHStruct. It provides an interface for the default BVH implementation, as well as for the BVH SAH implementation and the Kd-Tree. The SAH BVH overwrites the build function of the default BVH.</p>
	  <p>To realize the centroid-based SAH BVH construction described in Wald's paper, we had to extend the CentroidWIthID structure to store left and right-handed areas. Also the BBox now has a function to report back it's surface area.<p/>
	  <p>Also the Makefile has been modified to accept the parameter _NO_ACCELERATION=1 for disabling any acceleration structures and using the default BVH.</p>
	  <p>You can find the implementation in <i><u>rt/bvh.h</u></i>, <i><u>rt/bvhsah.cpp</u></i>, <u><i>rt/geometry_group.h</u></i>, <u><i>core/bbox.h</u></i> and <u><i>core/defs.h</u></i>.</p>
	  </div>

	<div class="contentSubSubTitle">References</div>
          <div class="contentText">
	  [1] Ingo Wald, Solomon Boulos, and Peter Shirley. Ray tracing deformable scenes using dynamic bounding volume hierarchies. ACM Trans. Graph., 26(1):6, 2007.<br/>
	  </div>
	<br/><hr />

	<a name="topic_kd"></a>
        <div class="contentTitle">SAH KD Tree (40 points)</div>
        <div class="contentSubTitle">- Optimization Techniques -<br/>Implemented by Frederik Leonhardt</div>
	<div class="contentSubSubTitle">Description</div>
          <div class="contentText">
	  <p>A kD-tree allows faster traversal, because split axis and split position are saved in the nodes. Also the <i>Surface Area Heuristic</i> can be used with kD-trees.</p>
	  <p>In contrast to a BVH in a kD-tree primitives can belong to several nodes, if the bounding box does overlap them.</p>
	  </div>

	<div class="contentSubSubTitle">Implementation</div>
<div class="contentText">
	  <p>The kD-tree inherits the interface from BVHStruct like our BVH implementation, but the internal structure differs hugely.</p>
	  <p>The SAH doesn't work centroid-based, primitives and additional information like split axis & position are saved in the nodes while building the tree. Later only references to the original primitives are saved in the leafs.<p/>
	  <p>We used the algorithm described in Wald/Havran's paper with a complexity of O(N log^2 N).</p>
	  <p>You can find the implementation in <i><u>rt/kdtree.h</u></i> and <i><u>rt/kdtree.cpp</u></i>.</p>
	  </div>

	<div class="contentSubSubTitle">Performance</div>
	  <div class="contentText">
	  <p>We built four scenes with varying complexity to evaluate the performance of our acceleration structures:</p>
    	<div id="inlinePicture">
    		<div class="kd_picture1"></div>
    	</div>
	<p>Scene 1: 7690 triangles.</p>
    	<div id="inlinePicture">
    		<div class="kd_picture2"></div>
    	</div>
	<p>Scene 1: 19210 triangles.</p>
    	<div id="inlinePicture">
    		<div class="kd_picture3"></div>
    	</div>
	<p>Scene 1: 34570 triangles.</p>
    	<div id="inlinePicture">
    		<div class="kd_picture4"></div>
    	</div>
	<p>Scene 4: 2614252 triangles.</p>

	<p><b>Default BVH:</b><br/>
	<table border="1">
	<tr>
	<td>Scene</td>
	<td>Structure build time</td>
	<td>Rendering time</td>
	<td>Number of leafs</td>
	</tr>
	<tr>
	<td>Scene 1</td>
	<td>29ms</td>
	<td>14s</td>
	<td>4516</td>
	</tr>
	<tr>
	<td>Scene 2</td>
	<td>57ms</td>
	<td>17s</td>
	<td>11285</td>
	</tr>
	<tr>
	<td>Scene 3</td>
	<td>95ms</td>
	<td>18s</td>
	<td>20274</td>
	</tr>
	<tr>
	<td>Scene 4</td>
	<td>8643ms</td>
	<td>14s</td>
	<td>1619757</td>
	</tr>
	</table> 
	</p>

	<p><b>SAH BVH:</b><br/>
	<table border="1">
	<tr>
	<td>Scene</td>
	<td>Structure build time</td>
	<td>Rendering time</td>
	<td>Number of leafs</td>
	</tr>
	<tr>
	<td>Scene 1</td>
	<td>129ms</td>
	<td>6s</td>
	<td>2208</td>
	</tr>
	<tr>
	<td>Scene 2</td>
	<td>320ms</td>
	<td>14s</td>
	<td>5524</td>
	</tr>
	<tr>
	<td>Scene 3</td>
	<td>567ms</td>
	<td>16s</td>
	<td>9897</td>
	</tr>
	<tr>
	<td>Scene 4</td>
	<td>68519ms</td>
	<td>14s</td>
	<td>795144</td>
	</tr>
	</table> 
	</p>

	<p><b>KD-Tree:</b><br/>
	<table border="1">
	<tr>
	<td>Scene</td>
	<td>Structure build time</td>
	<td>Rendering time</td>
	<td>Number of leafs</td>
	</tr>
	<tr>
	<td>Scene 1</td>
	<td>1460ms</td>
	<td>91s</td>
	<td>10345</td>
	</tr>
	<tr>
	<td>Scene 2</td>
	<td>10292ms</td>
	<td>479s</td>
	<td>15320</td>
	</tr>
	<tr>
	<td>Scene 3</td>
	<td>??</td>
	<td>??</td>
	<td>??</td>
	</tr>
	<tr>
	<td>Scene 4</td>
	<td>??</td>
	<td>??</td>
	<td>??</td>
	</tr>
	</table> 
	</p>

	<p>As you can see, our KD-Tree implementation did not perform very well. We didn't have the time to tune the parameters of the cost function, so we decided not to test Scene 3 and 4 anymore.</p>
	  </div>

	<div class="contentSubSubTitle">References</div>
          <div class="contentText">
	  [1] Ingo Wald and Vlastimil Havran. On building fast kd-trees for ray tracing, and on doing that in O(N log N)<br/>
	  </div>
	<br/><hr />

	<a name="topic_photon"></a>
        <div class="contentTitle">Photon Mapping (100 points)</div>
        <div class="contentSubTitle">- Advanced Topics -<br/>Implemented by Michael Frey</div>
	<div class="contentSubSubTitle">Description</div>         
	 <div class="contentText">
	 <p>A photon map is one way to implement global illumination into a raytracer. The Idea is to shoot a specified number of "Photons" into the Scene and save them in a map for later lookup during rendering.</p>
	 <p>We divide the specified number of photons by the number of light sources, so that the amount of photons in the scene is always the same, no matter how many lightsources we use. Via the intensity of the lightsource we can control the percentage of photons it distributes.</p>
	 <p>The photons are traced from the lightsource in a random direction. If a photons intersects an object we use russian roulette to determine what happens with the photons. Depending on the objects shader, the photon can either be absorbed, randomly reflected (diffuse), reflected or refracted.</p>
	 <p>If a photon hits a diffuse surface, the photon will be stored in the photon map(kd tree), if it has bounced one time prior to intersecting this surface( so we don't save direct illumination).</p>
	 <p>Because it is not possible to implement caustics (light that was refracted by a refractiv surface) in a raytracer via shadow rays (the possibility that the shadow rays will hit the light source is very low, because they will be refracted) you can approximate them by using a second photon map named <i>"caustic map"</i>. Each photon that has intersected a refractive surface will be flagged and if it hits a diffuse surface later it won't be stored in the normal photon map but in the caustic map.</p>
	 <p>You can observe the photon map in our final image especially under refractive surfaces (caustics). Also the water looks better and the general light looks more realistic.
	 </div>
        
	<div class="contentSubSubTitle">Implementation</div>
	 <div class="contentText">
	 <p>We based our implementation on a left balanced KD-Tree developed by Henrik Wann Jensen for storing the photons.</p>
	 <p>To use the photon map we extended our integrator with the functions <i>"shootPhotons"</i> and <i>"traceAPhoton"</i>. "shootPhotons" calculates the amount of photons per lightsource and their power based uppon the number of lightsources and the total number of photons and finally calls traceAPhoton for every photon.
	 <p>"traceAPhoton" traces a ray depending on a random direction, given by "shootPhotons" and checks for intersections. If we intesect an object, russian roulette determines what happens next (should we trace another photon or stop).</p>
	 <p>We had to adjust the shaders so that we can get the normals, reflection and refraction direction and probabilities for a given ray and surface. If we intersect with a diffuse surface we call the store function of our photon map, which inserts the given photon into an given array(photonMap) or if it has intersected with an reflective or refractive surface earlier we store it into an caustic map.</p>
	 <p>After "shootPhotons" is finished, we call the function balancePhotonMap which transformes our photonMap and causticMap from an unsorted Array into a left balanced KdTree.</p>
	 <p>When our raytracer intersects a surface in the scene the getRadiance function will be called like before. The only difference is that we add the irradiance after determining the color. The irradiance is calculated by accumulating the wheighted power of a given number of photons in a given sphere around the intersection point. The photons are given by the locatePhotons function in the photonMap.</p>
	  <p>You can find the implementation in <i><u>rt/myphotonmap.h</u></i>, <i><u>rt/myphotonmap.cpp</u></i>, <i><u>impl/photonMapping_Integrator.h.cpp</u></i> and <u><i>impl/phong_shaders.h</u></i>.</p>
	 </div>

	<div class="contentSubSubTitle">Examples</div>
    	<div id="inlinePictureSmall">
    		<div class="photon_picture"></div>
    	</div>
          <div class="contentText">A first test, the sphere is illuminated indirectly from photons bouncing off the floor.</div>   
    	
	<div id="inlinePictureSmall">
    		<div class="photon_picture2"></div>
    	</div>
          <div class="contentText">Our scene without photon mapping..</div>   

	<div id="inlinePictureSmall">
    		<div class="photon_picture3"></div>
    	</div>
          <div class="contentText">... and with photon mapping.</div>   
		
	<div class="contentSubSubTitle">References</div>
          <div class="contentText">
	  [1] Henrik Wann Jensen: A Practical Guide to Global Illumination using Photon Maps, Siggraph 2000 Course 8
	  </div>

	<br/><hr />

	<a name="topic_misc"></a>
        <div class="contentTitle">Misc</div>
        <div class="contentSubTitle">- Not listed -<br/>Implemented by Frederik Leonhardt & Michael Frey</div>
	<div class="contentSubSubTitle">Tile rendering</div>         
          <div class="contentText"><p>The renderer accepts a tile size and will not render the picture in scanlines, but in tiles. We hoped to gain a little performance increase through caching, but it didn't impact the rendering time. But now we can easily save tiles and start rendering at a given tile (very useful for long renders).</p></div>
	<div class="contentSubSubTitle">Orthographic camera</div>         
          <div class="contentText"><p>A camera which shoots parallel rays.</p></div>
        </div>
	</div>
    </div>

        <div id="footer">Design based on work by <a href="http://www.bryantsmith.com">bryant smith</a> | Modifications by Frederik Leonhardt </div>
</body>
</html>
